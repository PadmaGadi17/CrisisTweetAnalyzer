{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5498a8cc-0fc2-4436-91e4-e28fa487f7e8",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "During climate disasters like floods, cyclones,EarthQuake a huge amount of information spreads rapidly on Twitter, news sites, and messaging platforms. While some of this information is genuine—such as alerts, rescue details, and safety instructions—much of it can be false, including rumors, fake donation links, or misleading advice.\n",
    "This misinformation not only creates panic but also makes it harder for people and relief organizations to respond effectively during crises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b28f3b-23f9-4195-b7cd-dd8c48cf3b8c",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "The aim of this project is to build an application that can automatically check whether a tweet or news headline about climate disasters is real or fake. By applying techniques from Natural Language Processing (NLP), the system will help filter out false information and ensure that only reliable updates are highlighted. This can support people and organizations in making better decisions during emergencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "885ddb77-66a7-4e8e-aad6-921b161d830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce4223e-2d38-48d7-a030-e85e26c30d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"D:/Crisis-Tweet-Analyzer/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f808489b-7988-4ba3-9fa8-1346e0d0ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(\"D:/Crisis-Tweet-Analyzer/true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cc9bf8b-9eda-45a1-8e4b-ccfe0242de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_df = pd.read_csv(\"D:/Crisis-Tweet-Analyzer/Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd65a616-ba0f-435e-b679-77396dcb96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n",
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "                 id      target\n",
      "count   7613.000000  7613.00000\n",
      "mean    5441.934848     0.42966\n",
      "std     3137.116090     0.49506\n",
      "min        1.000000     0.00000\n",
      "25%     2734.000000     0.00000\n",
      "50%     5408.000000     0.00000\n",
      "75%     8146.000000     1.00000\n",
      "max    10873.000000     1.00000\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "\n",
    "print(train_df.info())\n",
    "\n",
    "# Checkind for missing values\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1388cdc-00de-4106-82d2-bfc4c77ca256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
